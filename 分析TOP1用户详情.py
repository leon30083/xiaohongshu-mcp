import json
import pandas as pd
from datetime import datetime

# Load the user profile data
with open('å¼€æŒ–æ˜æœºçš„å°ä¹ä¹_ç”¨æˆ·èµ„æ–™.json', 'r', encoding='utf-8-sig') as f:
    user_data = json.load(f)

# Extract user basic info
user_info = user_data['data']['data']['userBasicInfo']
interactions = user_data['data']['data']['interactions']
feeds = user_data['data']['data']['feeds']

print("=" * 80)
print("ğŸ† TOP1 UPä¸»æ·±åº¦åˆ†ææŠ¥å‘Šï¼šå¼€æŒ–æ˜æœºçš„å°ä¹ä¹")
print("=" * 80)

print("\nğŸ“Š åŸºæœ¬ä¿¡æ¯:")
print(f"æ˜µç§°: {user_info['nickname']}")
print(f"å°çº¢ä¹¦å·: {user_info['redId']}")
print(f"æ€§åˆ«: {'ç”·' if user_info['gender'] == 1 else 'å¥³'}")
print(f"IPå½’å±åœ°: {user_info['ipLocation']}")
print(f"ä¸ªäººç®€ä»‹: {user_info['desc']}")

print("\nğŸ“ˆ è´¦å·æ•°æ®:")
for interaction in interactions:
    print(f"{interaction['name']}: {interaction['count']}")

print("\nğŸ¯ å†…å®¹åˆ†æ:")
print(f"æ€»ä½œå“æ•°: {len(feeds)} æ¡")

# Analyze content types
video_count = sum(1 for feed in feeds if feed['noteCard']['type'] == 'video')
normal_count = sum(1 for feed in feeds if feed['noteCard']['type'] == 'normal')

print(f"è§†é¢‘å†…å®¹: {video_count} æ¡ ({video_count/len(feeds)*100:.1f}%)")
print(f"å›¾æ–‡å†…å®¹: {normal_count} æ¡ ({normal_count/len(feeds)*100:.1f}%)")

# Analyze content themes
story_count = 0
science_count = 0
daily_count = 0
travel_count = 0

content_analysis = []

for i, feed in enumerate(feeds):
    title = feed['noteCard']['displayTitle']
    content_type = feed['noteCard']['type']
    
    # Extract interaction data (some might be empty strings)
    liked_count = int(feed['noteCard']['interactInfo']['likedCount']) if feed['noteCard']['interactInfo']['likedCount'] else 0
    shared_count = int(feed['noteCard']['interactInfo']['sharedCount']) if feed['noteCard']['interactInfo']['sharedCount'] else 0
    comment_count = int(feed['noteCard']['interactInfo']['commentCount']) if feed['noteCard']['interactInfo']['commentCount'] else 0
    collected_count = int(feed['noteCard']['interactInfo']['collectedCount']) if feed['noteCard']['interactInfo']['collectedCount'] else 0
    
    # Categorize content
    category = "å…¶ä»–"
    if "å„¿ç«¥æ•…äº‹" in title or "æ•…äº‹" in title:
        story_count += 1
        category = "å„¿ç«¥æ•…äº‹"
    elif "ç§‘æ™®" in title or "å¤" in title:
        science_count += 1
        category = "ç§‘æ™®æ•™è‚²"
    elif "æ‰¬å·" in title or "æ—©å¸‚" in title or "é›å¨ƒ" in title:
        daily_count += 1
        category = "æ—¥å¸¸ç”Ÿæ´»"
    elif "æ‰¬å·" in title:
        travel_count += 1
        category = "æ—…è¡Œåˆ†äº«"
    else:
        daily_count += 1
        category = "æ—¥å¸¸ç”Ÿæ´»"
    
    content_analysis.append({
        'index': i + 1,
        'title': title,
        'type': content_type,
        'category': category,
        'liked_count': liked_count,
        'shared_count': shared_count,
        'comment_count': comment_count,
        'collected_count': collected_count,
        'total_interactions': liked_count + shared_count + comment_count + collected_count,
        'engagement_score': liked_count * 1 + shared_count * 3 + comment_count * 2 + collected_count * 4
    })

# Create DataFrame for analysis
df = pd.DataFrame(content_analysis)

print(f"\nğŸ­ å†…å®¹ä¸»é¢˜åˆ†å¸ƒ:")
print(f"å„¿ç«¥æ•…äº‹: {story_count} æ¡ ({story_count/len(feeds)*100:.1f}%)")
print(f"ç§‘æ™®æ•™è‚²: {science_count} æ¡ ({science_count/len(feeds)*100:.1f}%)")
print(f"æ—¥å¸¸ç”Ÿæ´»: {daily_count} æ¡ ({daily_count/len(feeds)*100:.1f}%)")

# Top performing content
top_content = df.nlargest(5, 'engagement_score')

print(f"\nğŸ”¥ TOP 5 é«˜ä»·å€¼ä½œå“:")
for i, (_, row) in enumerate(top_content.iterrows(), 1):
    print(f"{i}. ã€Š{row['title']}ã€‹")
    print(f"   ç±»å‹: {row['type']} | ä¸»é¢˜: {row['category']}")
    print(f"   äº’åŠ¨å¾—åˆ†: {row['engagement_score']:,.0f}")
    print(f"   ç‚¹èµ: {row['liked_count']:,} | æ”¶è—: {row['collected_count']:,} | åˆ†äº«: {row['shared_count']:,} | è¯„è®º: {row['comment_count']:,}")
    print()

# Content pattern analysis
print("ğŸ“‹ å†…å®¹åˆ›ä½œæ¨¡å¼åˆ†æ:")

# Story numbering pattern
story_titles = [item['title'] for item in content_analysis if 'å„¿ç«¥æ•…äº‹' in item['title']]
numbered_stories = [title for title in story_titles if any(char.isdigit() for char in title)]

print(f"1. ç³»åˆ—åŒ–åˆ›ä½œ: å„¿ç«¥æ•…äº‹ç³»åˆ—å·²åˆ›ä½œ {len(numbered_stories)} é›†")

# Extract story numbers
story_numbers = []
for title in numbered_stories:
    import re
    numbers = re.findall(r'\d+', title)
    if numbers:
        story_numbers.extend([int(num) for num in numbers])

if story_numbers:
    print(f"   æœ€æ–°é›†æ•°: ç¬¬{max(story_numbers)}é›†")
    print(f"   æ›´æ–°é¢‘ç‡: æŒç»­æ›´æ–°ä¸­")

print(f"2. å†…å®¹å½¢å¼: ä»¥è§†é¢‘ä¸ºä¸» ({video_count/len(feeds)*100:.1f}%)")
print(f"3. ä¸»é¢˜èšç„¦: å„¿ç«¥æ•™è‚²å†…å®¹å æ¯” {(story_count + science_count)/len(feeds)*100:.1f}%")

# Engagement analysis
avg_engagement = df['engagement_score'].mean()
print(f"4. å¹³å‡äº’åŠ¨å¾—åˆ†: {avg_engagement:,.0f}")

# Category performance
category_performance = df.groupby('category').agg({
    'engagement_score': ['mean', 'sum', 'count'],
    'liked_count': 'mean',
    'collected_count': 'mean'
}).round(2)

print(f"\nğŸ“Š å„ç±»å†…å®¹è¡¨ç°:")
for category in df['category'].unique():
    cat_data = df[df['category'] == category]
    avg_score = cat_data['engagement_score'].mean()
    count = len(cat_data)
    print(f"{category}: å¹³å‡å¾—åˆ† {avg_score:,.0f} ({count}æ¡)")

# Save detailed analysis
df.to_csv('å¼€æŒ–æ˜æœºçš„å°ä¹ä¹_å†…å®¹è¯¦ç»†åˆ†æ.csv', index=False, encoding='utf-8-sig')

print(f"\nâœ… è¯¦ç»†åˆ†ææ•°æ®å·²ä¿å­˜åˆ°: å¼€æŒ–æ˜æœºçš„å°ä¹ä¹_å†…å®¹è¯¦ç»†åˆ†æ.csv")

# Content creation insights
print(f"\nğŸ¯ å†…å®¹åˆ›ä½œæ´å¯Ÿ:")
print("1. å‚ç›´å®šä½æ˜ç¡®: ä¸“æ³¨å„¿ç«¥æ•™è‚²å†…å®¹")
print("2. ç³»åˆ—åŒ–è¿è¥: å„¿ç«¥æ•…äº‹ç¼–å·åŒ–ï¼Œä¾¿äºç”¨æˆ·è¿½æ›´")
print("3. æ•™è‚²ä»·å€¼å¯¼å‘: æ•…äº‹ä¸»é¢˜å¤šæ¶‰åŠå“æ ¼æ•™è‚²")
print("4. æŒç»­æ›´æ–°: ä¿æŒç¨³å®šçš„å†…å®¹è¾“å‡º")
print("5. å¤šå…ƒåŒ–å†…å®¹: æ•…äº‹+ç§‘æ™®+ç”Ÿæ´»ï¼Œæ»¡è¶³ä¸åŒéœ€æ±‚")

# Extract content creation formula
print(f"\nğŸ”§ å†…å®¹åˆ›ä½œå…¬å¼æå–:")
print("æ ‡é¢˜å…¬å¼: 'å„¿ç«¥æ•…äº‹[ç¼–å·]ï¼š[æ•™è‚²ä¸»é¢˜/ä»·å€¼è§‚]'")
print("å†…å®¹ç»“æ„: æ•…äº‹æƒ…èŠ‚ + æ•™è‚²æ„ä¹‰ + äº’åŠ¨å¼•å¯¼")
print("å‘å¸ƒé¢‘ç‡: æŒç»­ç¨³å®šæ›´æ–°")
print("å†…å®¹æ—¶é•¿: é€‚åˆå„¿ç«¥æ³¨æ„åŠ›çš„çŸ­è§†é¢‘")
print("äº’åŠ¨ç­–ç•¥: é€šè¿‡æ•…äº‹å¼•å‘å®¶é•¿å…±é¸£å’Œæ”¶è—")